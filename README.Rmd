---
output: github_document
---

# CoMET: A Compressed Bayesian Mixed-Effects Model for High-Dimensional Tensors

This repositary contains:

1. **R package BayesCoMET**
    - Implements the Compressed Bayesian Mixed-Effects Model for Tensors (CoMET).
    - Install this library with:
    ```{r, eval = FALSE}
    devtools::install_github("SreyaSarkar21/BayesCoMET")
    library(BayesCoMET)
    ```
    
2. **Others Folder**
    - contains the codes implementing the competing methods.
    - `sampler_Oracle.R` contains the code for oracle, the Bayesian oracle benchmark of CoMET, where the true random-effects covariance structure is known.
    - `fanli2012.R` contains the code for implementing the penalized quasi-likelihood method for fixed effects selection by [1].
    - `licaili2021.R` contains the code implementing the penalized quasi-likelihood estimation and inference procedures for fixed effects selection by [2], using their published supplementary code as a reference.
    - `gee_cv.m`, `gee_equicorr_predict.m`, `gee_run_DEAM.m` are the MATLAB codes using the SparseReg MATLAB library for implementing the GEE approach [3]. 


## Example Implementation of CoMET

```{r MargPred, message=FALSE, warning=FALSE}
library(BayesCoMET)
pdims <- qdims <- c(32, 32)
n_train <- 100; n_test <- 50; m <- 9 ## 9 observations per subject

library(BayesCoMET)

## Generating a  CP-structured fixed-effect coefficient
cp_decomp_B <- BayesCoMET:::generate_cpB_with_sparse_factors(pdims = c(32, 32), K = 4,
                                                             sparsity = 0.25, seed = 123)
trueB <- cp_decomp_B$B

## Equicorrelation covariance matrices per tensor-mode
equicorr_mat <- function(q, rho) {
    if(rho < -1/(q-1) | rho > 1) {
        stop(sprintf("For q = %d, rho must be in [-1/(q-1), 1] for postive semi-definiteness.", q))
    }
    Sigma <- matrix(rho, q, q)
    diag(Sigma) <- 1
    Sigma
}

Sigma1 <- Sigma2 <- equicorr_mat(q = 32, rho = 0.5)
L1 <- chol(Sigma1); L2 <- chol(Sigma2)

## Simulating data with 150 subjects each with cluster size m
dat <- BayesCoMET:::simdata(pdims = c(32, 32), qdims = c(32, 32), n = 150, m = m,
                            errVar = 0.1, B = trueB, L_list = list(L1 = L1, L2 = L2),
                            xcov_var = 1, zcov_var = 1, myseed = 1)

## Taking first 100 subjects for training and the rest for validation
y_train <- dat$yijs[1:(n_train * m)]; y_test <- dat$yijs[(n_train * m + 1):length(dat$yijs)]
xlist_train <- dat$Xijlist[1:(n_train * m)]; xlist_test <- dat$Xijlist[(n_train * m + 1):length(dat$yijs)]
zlist_train <- dat$Zijlist[1:(n_train * m)]; zlist_test <- dat$Zijlist[(n_train * m + 1):length(dat$yijs)]
nmodes <- length(pdims)

## Implement CoMET model Gibbs sampler
kdims <- rep(3, nmodes)
set.seed(12345)
R_list <- lapply(1:nmodes, function(d) {matrix(rnorm(kdims[d] * qdims[d], 0, sd = sqrt(1/kdims[d])), kdims[d], qdims[d])})
S_list <- lapply(1:nmodes, function(d) {matrix(rnorm(kdims[d] * qdims[d], 0, sd = sqrt(1/kdims[d])), kdims[d], qdims[d])})

res <- BayesCoMET::comet(y = y_train, xlist = xlist_train, zlist = zlist_train,
                         mis = rep(m, times = n_train),
                         K = 6, kdims = kdims, a0 = 0.01, b0 = 0.01, gammaVar0 = c(1, 1),
                         R_list = R_list, S_list = S_list,
                         niter = 11000, nburn = 1000, nthin = 1, store_ranef = FALSE)

## Time taken in minutes ##
res$sampler_time / 60

betaPostMed <- apply(res$betaSamp, 2, median)
vecB_true <- as.vector(trueB)

pred_res <- BayesCoMET::predict_newsubj(object = res, kdims = kdims,
                                        R_list = R_list, S_list = S_list,
                                        y_test = y_test, xlist_test = xlist_test,
                                        zlist_test = zlist_test,
                                        mis = rep(m, times = n_test), nom.level = 0.95)

```


```{r visualize_betaSamps, echo=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=4}
library(dplyr)
library(ggplot2)
library(ggpubr)

idx <- c("438", "439")
niter <- 10000

beta_df <- data.frame(
  postsamp = c(res$betaSamp[, 438], res$betaSamp[, 439]),
  betaidx  = factor(rep(idx, each = niter), levels = idx))

bsumm_df <- data.frame(
  q025 = c(quantile(res$betaSamp[, 438], 0.025), quantile(res$betaSamp[, 439], 0.025)),
  q50 = c(median(res$betaSamp[, 438]), median(res$betaSamp[, 439])),
  q975 = c(quantile(res$betaSamp[, 438], 0.975), quantile(res$betaSamp[, 439], 0.975)),
  true = c(vecB_true[438], vecB_true[439]),
  betaidx = factor(idx, levels = idx))

make_hist <- function(bname) {
  s <- filter(bsumm_df, betaidx == bname)

  ggplot(filter(beta_df, betaidx == bname), aes(x = postsamp)) +
    geom_histogram(aes(y = after_stat(density)),
                   bins = 25, fill = "lightgrey", color = "black") +

    # 95% CI (two dashed lines, same legend key via color)
    geom_vline(aes(xintercept = s$q025, color = "95% CI"), linetype = 2, linewidth = 0.8) +
    geom_vline(aes(xintercept = s$q975, color = "95% CI"), linetype = 2, linewidth = 0.8) +

    # Posterior median (dotted)
    geom_vline(aes(xintercept = s$q50, color = "Posterior median"), linetype = 3, linewidth = 0.9) +

    # True value (solid)
    geom_vline(aes(xintercept = s$true, color = "True value"), linetype = 1, linewidth = 0.9) +

    labs(x = bquote(beta[.(bname)]), y = "Density") +
    theme_bw() +
    theme(
      legend.position = "bottom",
      plot.title = element_blank()
    ) +
    guides(color = guide_legend(title = NULL))
}

h1 <- make_hist("438")
h2 <- make_hist("439")

fig_beta <- ggarrange(h1, h2, ncol = 2, common.legend = TRUE, legend = "bottom")
fig_beta <- annotate_figure(fig_beta, top = text_grob("Histogram of Posterior Samples of B", size = 10, face = "bold"))
fig_beta
```

```{r visualize_ySamps, echo=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=4}
library(dplyr)
library(ggplot2)
library(ggpubr)

idx <- c("11", "12")
niter <- 10000

y_df <- data.frame(
  postsamp = c(pred_res$yhat_samples[[1]][1, ], pred_res$yhat_samples[[1]][2, ]),
  yidx  = factor(rep(idx, each = niter), levels = idx))

ysumm_df <- data.frame(
  q025 = c(pred_res$lower_pi[[1]][1], pred_res$lower_pi[[1]][2]),
  q50 = c(quantile(pred_res$yhat_samples[[1]][1, ], 0.50), quantile(pred_res$yhat_samples[[1]][2, ], 0.50)),
  q975 = c(pred_res$upper_pi[[1]][1], pred_res$upper_pi[[1]][2]),
  true = c(y_test[1], y_test[2]),
  yidx = factor(idx, levels = idx))

make_hist <- function(bname) {
  s <- filter(ysumm_df, yidx == bname)

  ggplot(filter(y_df, yidx == bname), aes(x = postsamp)) +
    geom_histogram(aes(y = after_stat(density)),
                   bins = 25, fill = "lightgrey", color = "black") +

    # 95% CI (two dashed lines, same legend key via color)
    geom_vline(aes(xintercept = s$q025, color = "95% CI"), linetype = 2, linewidth = 0.8) +
    geom_vline(aes(xintercept = s$q975, color = "95% CI"), linetype = 2, linewidth = 0.8) +

    # Posterior mean (dotted)
    geom_vline(aes(xintercept = s$q50, color = "Posterior median"), linetype = 3, linewidth = 0.9) +

    # True value (solid)
    geom_vline(aes(xintercept = s$true, color = "True value"), linetype = 1, linewidth = 0.9) +

    labs(x = bquote(y[.(bname)]^{plain(new)}), y = "Density") +
    theme_bw() +
    theme(
      legend.position = "bottom",
      plot.title = element_blank()
    ) +
    guides(color = guide_legend(title = NULL))
}

h1 <- make_hist("11")
h2 <- make_hist("12")

fig_pred <- ggarrange(h1, h2, ncol = 2, common.legend = TRUE, legend = "bottom")
fig_pred <- annotate_figure(fig_pred, top = text_grob("Histogram of Posterior Predictive Samples", size = 10, face = "bold"))
fig_pred
```





## Acknowledgement

Sreya Sarkar was supported by the National Science Foundation grant DMS-1854667 for this work.


## Citation

If you use *BayesCoMET* in your work, please cite:
Sarkar, S., Khare, K., & Srivastava, S. (2026). **CoMET: A Compressed Bayesian Mixed-Effects Model for High-Dimensional Tensors.** *arXiv.* [https://arxiv.org/pdf/2602.19236](https://arxiv.org/pdf/2602.19236)


## Other References

[1] Fan, Y., & Li, R. (2012). **Variable Selection in Linear Mixed Effects Models.** *The Annals of Statistics*, Vol. 40, No. 4, pp. 2043–2068. DOI: [10.1214/12-AOS1028](https://doi.org/10.1214/12-AOS1028).

[2] Li, S., Cai T. T., & Li, H. (2022). **Inference for High-Dimensional Linear Mixed-Effects Models: A Quasi-Likelihood Approach.** *Journal of the American Statistical Association*, 117(540), 1835–1846. DOI: [10.1080/01621459.2021.1888740](https://doi.org/10.1080/01621459.2021.1888740).

[3] Zhang X., Li, L., Zhou, H., Shen, D., et al. (2019). **Tensor generalized estimating equations for longitudinal imaging analysis.** *Statistica Sinica*, 29(4), 1977-2005. DOI: [10.5705/ss.202017.0153](https://doi.org/10.5705/ss.202017.0153).


